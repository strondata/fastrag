# ğŸš€ Guia RÃ¡pido de Uso

## InstalaÃ§Ã£o RÃ¡pida

```bash
# 1. Clonar repositÃ³rio
git clone https://github.com/strondata/fastrag.git
cd fastrag

# 2. Criar ambiente virtual (recomendado)
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# 3. Instalar dependÃªncias
pip install -r requirements.txt
```

## ConfiguraÃ§Ã£o do Ollama

### Linux/Mac
```bash
curl -fsSL https://ollama.com/install.sh | sh
ollama pull llama3
ollama serve
```

### Windows
1. Baixar de [ollama.com](https://ollama.com)
2. Instalar
3. Executar: `ollama pull llama3`

## Uso BÃ¡sico

### 1. Adicionar Documentos

Crie ou adicione seus arquivos `.txt` ou `.md` na pasta `data/`:

```bash
mkdir -p data
echo "Python Ã© uma linguagem de programaÃ§Ã£o." > data/python.txt
echo "O Brasil Ã© um paÃ­s da AmÃ©rica do Sul." > data/brasil.txt
```

### 2. Executar o Chatbot

```bash
streamlit run app.py
```

### 3. Usar a Interface Web

1. Abrir navegador em `http://localhost:8501`
2. Na sidebar, clicar em **"Alimentar RAG"**
3. Fazer perguntas no chat!

## Exemplo de Uso

**VocÃª**: O que Ã© Python?

**Bot**: Python Ã© uma linguagem de programaÃ§Ã£o de alto nÃ­vel, conhecida por sua sintaxe clara e legibilidade...

## DemonstraÃ§Ã£o sem Ollama

Se vocÃª quiser apenas ver o sistema funcionando sem instalar Ollama:

```bash
python demo.py
```

Este script usa um MockLLM e demonstra o fluxo completo.

## ValidaÃ§Ã£o da InstalaÃ§Ã£o

```bash
python validate.py
```

## Estrutura de Dados

Os documentos sÃ£o carregados de `./data/`:

```
data/
â”œâ”€â”€ documento1.txt
â”œâ”€â”€ documento2.txt
â””â”€â”€ notas.md
```

## PersonalizaÃ§Ã£o

### Alterar Modelo LLM

No Streamlit, edite o campo "Modelo LLM (Ollama)" na sidebar.

### Alterar NÃºmero de Resultados (k)

No cÃ³digo:
```python
response = chatbot.ask("Pergunta", k=5)  # Busca top 5 documentos
```

### Template de Prompt Customizado

```python
custom_template = """
Responda em portuguÃªs formal:
CONTEXTO: {context}
PERGUNTA: {question}
RESPOSTA:
"""

chatbot = RAGChatbot(..., prompt_template=custom_template)
```

## Troubleshooting

### Erro: "Ollama nÃ£o estÃ¡ rodando"
```bash
ollama serve
```

### Erro: "Modelo nÃ£o encontrado"
```bash
ollama pull llama3
```

### Erro: MÃ³dulo nÃ£o encontrado
```bash
pip install -r requirements.txt
```

### Verificar Logs
```bash
cat logs/rag_chatbot.log
```

## Testes

```bash
# Todos os testes
pytest

# Com verbosidade
pytest -v

# Teste especÃ­fico
pytest tests/test_core.py
```

## Recursos AvanÃ§ados

### Usar ChromaDB Persistente

```python
from rag_chatbot.components.vector_stores import ChromaVectorStore

store = ChromaVectorStore(
    collection_name="meu_rag",
    persist_directory="./chroma_data"
)
```

### Criar Loader Customizado

```python
from rag_chatbot.interfaces import IDocumentLoader, Documento

class PDFLoader(IDocumentLoader):
    def load(self, source: str) -> List[Documento]:
        # Implementar leitura de PDF
        pass
```

### MÃºltiplas Fontes

```python
# Ingerir de vÃ¡rias pastas
chatbot.ingest_data("./data/docs")
chatbot.ingest_data("./data/articles")
chatbot.ingest_data("./data/notes")
```

## PrÃ³ximos Passos

1. âœ… Adicione seus documentos em `./data/`
2. âœ… Inicie o Ollama
3. âœ… Execute `streamlit run app.py`
4. âœ… Comece a fazer perguntas!

## Suporte

- ğŸ“– DocumentaÃ§Ã£o completa: [README.md](README.md)
- ğŸ› Issues: GitHub Issues
- ğŸ’¡ Exemplos: `demo.py`, `validate.py`

---

**Dica**: Comece com documentos pequenos para testar e depois expanda sua base de conhecimento!
