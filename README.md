# ü§ñ Chatbot RAG Local Personalizado

Sistema de Chatbot RAG (Retrieval-Augmented Generation) modular, extens√≠vel e test√°vel em Python, com interface Streamlit.

## üìã Vis√£o Geral

Este projeto implementa um chatbot que responde perguntas baseadas em uma base de conhecimento privada (documentos locais), utilizando:

- **RAG (Retrieval-Augmented Generation)**: Combina busca sem√¢ntica com gera√ß√£o de texto
- **LLM Local**: Usa Ollama para rodar modelos de linguagem localmente
- **Embeddings**: SentenceTransformers para vetoriza√ß√£o de texto
- **Vector Store**: ChromaDB para armazenamento e busca eficiente
- **UI**: Interface web interativa com Streamlit

### Princ√≠pios de Design (SOLID)

O sistema foi constru√≠do seguindo os princ√≠pios SOLID:

- **[S] Single Responsibility**: Cada classe tem uma responsabilidade √∫nica
- **[O] Open/Closed**: Aberto para extens√£o, fechado para modifica√ß√£o
- **[L] Liskov Substitution**: Componentes s√£o intercambi√°veis via interfaces
- **[I] Interface Segregation**: Interfaces pequenas e focadas
- **[D] Dependency Inversion**: Depend√™ncia de abstra√ß√µes, n√£o implementa√ß√µes

## üèóÔ∏è Estrutura do Projeto

```
/chatbot-rag-local/
‚îÇ
‚îú‚îÄ‚îÄ /data/                   # (Ignorado) Documentos do usu√°rio
‚îú‚îÄ‚îÄ /logs/                   # (Ignorado) Arquivos de log
‚îÇ
‚îú‚îÄ‚îÄ /rag_chatbot/            # Pacote principal
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ interfaces.py        # Interfaces abstratas (ABC)
‚îÇ   ‚îú‚îÄ‚îÄ core.py              # Orquestrador RAGChatbot
‚îÇ   ‚îú‚îÄ‚îÄ config.py            # Configura√ß√µes
‚îÇ   ‚îî‚îÄ‚îÄ /components/         # Implementa√ß√µes concretas
‚îÇ       ‚îú‚îÄ‚îÄ loaders.py       # FolderLoader
‚îÇ       ‚îú‚îÄ‚îÄ embedders.py     # MiniLMEmbedder
‚îÇ       ‚îú‚îÄ‚îÄ vector_stores.py # ChromaVectorStore
‚îÇ       ‚îî‚îÄ‚îÄ llms.py          # OllamaLLM, MockLLM
‚îÇ
‚îú‚îÄ‚îÄ /tests/                  # Testes
‚îÇ   ‚îú‚îÄ‚îÄ test_core.py         # Testes do RAGChatbot
‚îÇ   ‚îî‚îÄ‚îÄ test_components.py   # Testes dos componentes
‚îÇ
‚îú‚îÄ‚îÄ app.py                   # Aplicativo Streamlit
‚îú‚îÄ‚îÄ requirements.txt         # Depend√™ncias
‚îú‚îÄ‚îÄ README.md               # Esta documenta√ß√£o
‚îî‚îÄ‚îÄ .gitignore              # Arquivos ignorados
```

## üöÄ Instala√ß√£o

### 1. Clonar o Reposit√≥rio

```bash
git clone https://github.com/strondata/fastrag.git
cd fastrag
```

### 2. Criar Ambiente Virtual (Recomendado)

```bash
python -m venv .venv
source .venv/bin/activate  # No Windows: .venv\Scripts\activate
```

### 3. Instalar Depend√™ncias

```bash
pip install -r requirements.txt
```

### 4. Configurar LLM Local (Ollama)

#### Instalar Ollama

- **Linux/Mac**: 
  ```bash
  curl -fsSL https://ollama.com/install.sh | sh
  ```
- **Windows**: Baixar de [ollama.com](https://ollama.com)

#### Baixar um Modelo

```bash
ollama pull llama3
# Ou outros modelos: mistral, phi, gemma, etc.
```

#### Iniciar Ollama

```bash
ollama serve
```

## üìñ Uso

### Executar o Chatbot

```bash
streamlit run app.py
```

O aplicativo abrir√° em `http://localhost:8501`

### Alimentar a Base de Conhecimento

1. **Adicionar Documentos**: Coloque seus arquivos `.txt` ou `.md` na pasta `./data/`
   
   ```bash
   mkdir -p data
   echo "O cachorro √© marrom e amig√°vel." > data/animais.txt
   ```

2. **No Streamlit**: Clique no bot√£o **"Alimentar RAG"** na sidebar

3. **Fazer Perguntas**: Use o chat para interagir com sua base de conhecimento

### Exemplo de Uso

```
Usu√°rio: Qual a cor do cachorro?
Bot: O cachorro √© marrom.
```

## üß™ Testes

### Executar Todos os Testes

```bash
pytest
```

### Executar Testes Espec√≠ficos

```bash
# Testes do core
pytest tests/test_core.py

# Testes dos componentes
pytest tests/test_components.py

# Com verbosidade
pytest -v

# Com cobertura
pytest --cov=rag_chatbot
```

## üîß Configura√ß√£o Avan√ßada

### Personalizar Modelo LLM

Edite `rag_chatbot/config.py`:

```python
DEFAULT_LLM_MODEL = "mistral"  # ou outro modelo
```

Ou configure na interface do Streamlit.

### Personalizar Template de Prompt

```python
from rag_chatbot.core import RAGChatbot

custom_template = """
Responda em portugu√™s brasileiro:
CONTEXTO: {context}
PERGUNTA: {question}
RESPOSTA:
"""

chatbot = RAGChatbot(
    loader=loader,
    embedder=embedder,
    store=store,
    llm=llm,
    prompt_template=custom_template
)
```

### Usar Diferentes Componentes

```python
from rag_chatbot.components.loaders import FolderLoader
from rag_chatbot.components.embedders import MiniLMEmbedder
from rag_chatbot.components.vector_stores import ChromaVectorStore
from rag_chatbot.components.llms import OllamaLLM
from rag_chatbot.core import RAGChatbot

# Componentes customizados
loader = FolderLoader()
embedder = MiniLMEmbedder(model_name="paraphrase-multilingual-MiniLM-L12-v2")
store = ChromaVectorStore(collection_name="my_custom_rag")
llm = OllamaLLM(model_name="mistral")

chatbot = RAGChatbot(loader, embedder, store, llm)
```

## üìö API Reference

### RAGChatbot

```python
chatbot = RAGChatbot(loader, embedder, store, llm)

# Alimentar com dados
num_docs = chatbot.ingest_data("/path/to/data")

# Fazer pergunta
response = chatbot.ask("Sua pergunta aqui", k=3)

# Obter documentos fonte
sources = chatbot.get_sources("Pergunta", k=3)
```

### Interfaces

- `IDocumentLoader`: Carrega documentos de uma fonte
- `IEmbeddingModel`: Gera embeddings de texto
- `IVectorStore`: Armazena e busca vetores
- `ILocalLLM`: Gera texto com LLM local

## üêõ Troubleshooting

### Erro: "Pacote 'ollama' n√£o encontrado"

```bash
pip install ollama
```

### Erro: "Ollama n√£o est√° rodando"

```bash
ollama serve
```

### Erro: "Modelo n√£o encontrado"

```bash
ollama pull llama3
```

### Logs

Verifique os logs em `./logs/rag_chatbot.log` para debugging detalhado.

## ü§ù Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudan√ßas (`git commit -m 'feat: adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

### Padr√£o de Commits

Usamos [Conventional Commits](https://www.conventionalcommits.org/):

- `feat:` Nova funcionalidade
- `fix:` Corre√ß√£o de bug
- `docs:` Documenta√ß√£o
- `test:` Testes
- `refactor:` Refatora√ß√£o de c√≥digo

## üìÑ Licen√ßa

Este projeto √© de c√≥digo aberto.

## üë• Autores

- Desenvolvido seguindo especifica√ß√µes SOLID e boas pr√°ticas Python

## üîó Links √öteis

- [Ollama](https://ollama.com)
- [Streamlit](https://streamlit.io)
- [ChromaDB](https://www.trychroma.com)
- [SentenceTransformers](https://www.sbert.net)

---

**Nota**: Este √© um projeto educacional que demonstra implementa√ß√£o de RAG com arquitetura modular e princ√≠pios SOLID.
