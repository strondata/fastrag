#!/usr/bin/env python
"""Script de demonstraÃ§Ã£o do RAG Chatbot (sem necessidade de Ollama).

Este script demonstra o funcionamento do sistema RAG usando MockLLM,
que nÃ£o requer Ollama instalado.
"""

from src.rag_chatbot.core import RAGChatbot
from src.rag_chatbot.components.loaders import FolderLoader
from src.rag_chatbot.components.llms import MockLLM
from src.rag_chatbot.interfaces import IEmbeddingModel, IVectorStore, Documento
from typing import List


class SimpleEmbedder(IEmbeddingModel):
    """Embedder simples para demonstraÃ§Ã£o (nÃ£o usa ML real)."""
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        # Retorna embeddings fictÃ­cios baseados no comprimento
        return [[float(len(text)), float(text.count(' '))] for text in texts]
    
    def embed_query(self, text: str) -> List[float]:
        return [float(len(text)), float(text.count(' '))]


class SimpleVectorStore(IVectorStore):
    """Vector store simples para demonstraÃ§Ã£o (busca por palavra-chave)."""
    
    def __init__(self):
        self.documents = []
    
    def add(self, documents: List[Documento], embeddings: List[List[float]]) -> None:
        self.documents.extend(documents)
    
    def search(self, query_embedding: List[float], k: int) -> List[Documento]:
        # Retorna todos os documentos (busca simples)
        return self.documents[:k]


def main():
    """DemonstraÃ§Ã£o do sistema."""
    print("=" * 60)
    print("ğŸ¤– DemonstraÃ§Ã£o do Sistema RAG Chatbot")
    print("=" * 60)
    print()
    
    # Criar componentes simples
    print("ğŸ“¦ Inicializando componentes...")
    loader = FolderLoader()
    embedder = SimpleEmbedder()
    store = SimpleVectorStore()
    llm = MockLLM(default_response="Esta Ã© uma resposta de demonstraÃ§Ã£o. Em produÃ§Ã£o, usaria Ollama.")
    
    # Criar chatbot
    chatbot = RAGChatbot(loader, embedder, store, llm)
    print("âœ… Chatbot criado!")
    print()
    
    # Ingerir dados
    print("ğŸ“š Carregando base de conhecimento...")
    data_path = "./data"
    num_docs = chatbot.ingest_data(data_path)
    print(f"âœ… {num_docs} documento(s) carregado(s)")
    print()
    
    # Fazer algumas perguntas
    questions = [
        "O que Ã© este sistema?",
        "Quais sÃ£o as caracterÃ­sticas principais?",
        "Como usar o chatbot?"
    ]
    
    print("ğŸ’¬ Demonstrando perguntas e respostas:")
    print("-" * 60)
    
    for i, question in enumerate(questions, 1):
        print(f"\n[Pergunta {i}]: {question}")
        
        # Obter fontes
        sources = chatbot.get_sources(question, k=1)
        if sources:
            print(f"[Fonte]: {sources[0].metadata.get('source', 'N/A')}")
            print(f"[Contexto]: {sources[0].content[:100]}...")
        
        # Obter resposta
        response = chatbot.ask(question)
        print(f"[Resposta]: {response}")
    
    print()
    print("-" * 60)
    print()
    print("âœ¨ DemonstraÃ§Ã£o concluÃ­da!")
    print()
    print("ğŸ“ Nota: Este exemplo usa MockLLM para demonstraÃ§Ã£o.")
    print("   Para usar um LLM real, instale Ollama e use OllamaLLM.")
    print()
    print("ğŸš€ Para interface completa, execute: streamlit run app.py")
    print()


if __name__ == "__main__":
    main()
